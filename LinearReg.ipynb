{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n\n  LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n0         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n2         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n3         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n4         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n5         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n6         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n7         Lvl    AllPub  ...        0    NaN    NaN        Shed     350   \n8         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n9         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n0      2   2008        WD         Normal     208500  \n1      5   2007        WD         Normal     181500  \n2      9   2008        WD         Normal     223500  \n3      2   2006        WD        Abnorml     140000  \n4     12   2008        WD         Normal     250000  \n5     10   2009        WD         Normal     143000  \n6      8   2007        WD         Normal     307000  \n7     11   2009        WD         Normal     200000  \n8      4   2008        WD        Abnorml     129900  \n9      1   2008        WD         Normal     118000  \n\n[10 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "print(train[0:10])"
   ]
  },
  {
   "source": [
    "types = train.dtypes\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       RL\n1       RL\n2       RL\n3       RL\n4       RL\n        ..\n1455    RL\n1456    RL\n1457    RL\n1458    RL\n1459    RL\nName: MSZoning, Length: 1460, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "ke = train.columns[2]\n",
    "print(train[ke])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_dict = {}\n",
    "\n",
    "cat_labels = []\n",
    "new_arr = []\n",
    "first = True\n",
    "non_cat = []\n",
    "\n",
    "for ke, type in zip(train.columns, types):\n",
    "    if type == \"object\":\n",
    "        le = OneHotEncoder()\n",
    "        if train[ke].isnull().values.any():\n",
    "            ifnan = True\n",
    "        else:\n",
    "            ifnan = False\n",
    "\n",
    "        if ifnan:\n",
    "            unique = np.expand_dims(np.asarray([\"nan\"] + list(train[ke].dropna().unique())), axis = 1)\n",
    "        else:\n",
    "            unique = np.expand_dims(np.asarray(list(train[ke].dropna().unique())), axis = 1)\n",
    "\n",
    "\n",
    "        train[ke] = train[ke].fillna(\"nan\")\n",
    "\n",
    "        cat = le.fit_transform(np.expand_dims(train[ke], axis = 1)).toarray().T\n",
    "        if first:\n",
    "            first = False\n",
    "            categorical= cat\n",
    "        else:\n",
    "            categorical = np.concatenate((categorical, cat), axis = 0)\n",
    "\n",
    "        keys = le.categories_\n",
    "        ka = [k for k in keys]\n",
    "        cat_dict[ke] = ka\n",
    "        cat_labels.extend(ka)\n",
    "    else:\n",
    "        non_cat.append(ke)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = categorical.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1460, 304)\n"
     ]
    }
   ],
   "source": [
    "train_no_lab = train.iloc[:,1:-1]\n",
    "train_lab = train.iloc[:,-1]\n",
    "\n",
    "train_non_cat = train_no_lab[[t for t in train_no_lab.columns if t in non_cat]]\n",
    "\n",
    "train_arr = np.concatenate((train_non_cat, categorical), axis = 1)\n",
    "\n",
    "print(train_arr.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1460, 304)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "\n",
    "imputer.fit(train_arr)\n",
    "train_arr = imputer.transform(train_arr)\n",
    "print(train_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "##### Try Linear Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression(fit_intercept = False)\n",
    "reg.fit(train_arr, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.81879563 0.82198587 0.79982351 0.88558431 0.67080625]\n0.7993991142625093\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "train_pred = reg.predict(train_arr)\n",
    "train_score = reg.score(train_arr, train_lab)\n",
    "reg_scores = cross_val_score(reg, train_arr, train_lab, cv = 5)\n",
    "print(reg_scores)\n",
    "print(reg_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Trying LASSO\n",
    "from sklearn.linear_model import Lasso\n",
    "clf = Lasso(alpha=0.1)\n",
    "clf.fit(train_arr, train_lab)\n",
    "train_pred_lasso = clf.predict(train_arr)\n",
    "train_score_lasso = clf.score(train_arr, train_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.85706054 0.81845762 0.81089544 0.88835349 0.65434725]\n0.8058228689443153\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = cross_val_score(clf, train_arr, train_lab, cv = 5)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.810443551581948, 0.8105265649161406, 0.8106103849874724, 0.8106929912353728, 0.8107732327534773, 0.8108595302728286, 0.8109472437801497, 0.811034044989386, 0.8111185095037449, 0.811202494325444, 0.8112860215374951, 0.8113722212797583, 0.8114581698113925, 0.811541844023466, 0.8116236406700221, 0.8116992010972505, 0.8117729367532001, 0.8118618879826119, 0.8119872259355191, 0.8121109995468231, 0.8122307561203982, 0.8123495086937469, 0.8124666890859281, 0.8125837289095404, 0.8127008318408449, 0.8128148000767507, 0.8129277746199147, 0.8130401825339362, 0.8131515980039807, 0.8132624575826147, 0.813371378211078, 0.813475010687769, 0.8135772860192478, 0.8136789278558261, 0.8137798481411285, 0.813880355045856, 0.8139801916874825, 0.8140791854254701, 0.8141827223216419, 0.8142943383082575, 0.8144065477058178, 0.8145176076500494, 0.8146268165369183, 0.8147354028961328, 0.8148436787561231, 0.8149533593862316, 0.8150628762666472, 0.8151708194554518, 0.8152796179220443, 0.8153876412349363, 0.8154958026779349]\n"
     ]
    }
   ],
   "source": [
    "### hyperparameter tuning\n",
    "alphas = [s/10 for s in range(49,100)]\n",
    "cv_score = []\n",
    "for alp in range(49,100):\n",
    "    alp = alp/10\n",
    "    clf = Lasso(alpha=alp)\n",
    "    clf.fit(train_arr, train_lab)\n",
    "    train_pred_lasso = clf.predict(train_arr)\n",
    "    scores = cross_val_score(clf, train_arr, train_lab, cv = 5)\n",
    "    cv_score.append(scores.mean())\n",
    "\n",
    "print(cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8154958026779349\n[9.9]\n"
     ]
    }
   ],
   "source": [
    "max_val = max(cv_score)\n",
    "indices_max = [i for i,v in enumerate(cv_score) if v == max_val]\n",
    "print(max_val)\n",
    "max_alphas = [v for i,v in enumerate(alphas) if i in indices_max]\n",
    "print(max_alphas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.86628579 0.8181168  0.848929   0.84852352 0.64645998]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "regr = ElasticNet(random_state=0)\n",
    "regr.fit(train_arr, train_lab)\n",
    "el_scores = cross_val_score(regr, train_arr, train_lab, cv = 5)\n",
    "print(el_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_el = [s/20 for s in range(1,20)]\n",
    "cv_score_el = []\n",
    "for alp in range(1,20):\n",
    "    alp = alp/20\n",
    "    regr = ElasticNet(alpha = alp, random_state=0)\n",
    "    regr.fit(train_arr, train_lab)\n",
    "    scores = cross_val_score(regr, train_arr, train_lab, cv = 5)\n",
    "    cv_score_el.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8390617568482248\n[0.05]\n"
     ]
    }
   ],
   "source": [
    "max_val = max(cv_score_el)\n",
    "indices_max = [i for i,v in enumerate(cv_score_el) if v == max_val]\n",
    "print(max_val)\n",
    "max_alphas_el = [v for i,v in enumerate(alphas_el) if i in indices_max]\n",
    "print(max_alphas_el)"
   ]
  },
  {
   "source": [
    "## Regression Trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "random_forest = RandomForestRegressor(max_depth = 10, random_state = 0)\n",
    "random_forest.fit(train_arr, train_lab)\n",
    "scores = random_forest.score(train_arr, train_lab)\n",
    "scores_cv = cross_val_score(random_forest, train_arr, train_lab, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hyperparameter tuning\n",
    "alphas_rf = [s for s in range(2,20)]\n",
    "cv_score_rf = []\n",
    "for alp in range(2,20):\n",
    "    regr = RandomForestRegressor(max_depth = alp, random_state = 0)\n",
    "    regr.fit(train_arr, train_lab)\n",
    "    scores = cross_val_score(regr, train_arr, train_lab, cv = 5)\n",
    "    cv_score_rf.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8580253696033024\n[13]\n"
     ]
    }
   ],
   "source": [
    "max_val = max(cv_score_rf)\n",
    "indices_max = [i for i,v in enumerate(cv_score_rf) if v == max_val]\n",
    "print(max_val)\n",
    "max_alphas_rf = [v for i,v in enumerate(alphas_rf) if i in indices_max]\n",
    "print(max_alphas_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12:55:05] WARNING: /tmp/pip-build-212ww3zp/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:55:07] WARNING: /tmp/pip-build-212ww3zp/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:55:09] WARNING: /tmp/pip-build-212ww3zp/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:55:10] WARNING: /tmp/pip-build-212ww3zp/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:55:12] WARNING: /tmp/pip-build-212ww3zp/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsmample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "scores = cross_val_score(xg_reg, train_arr, train_lab, cv = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.06951738  0.02899955  0.03172444 -0.00803094  0.00866335]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "1bc38c910a2ac97386b6bf799a99b19782d7443e84f16a63e9afccf77f0414b4"
    }
   }
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}