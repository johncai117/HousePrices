{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n\n  LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n0         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n2         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n3         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n4         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n5         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n6         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n7         Lvl    AllPub  ...        0    NaN    NaN        Shed     350   \n8         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n9         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n\n  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n0      2   2008        WD         Normal     208500  \n1      5   2007        WD         Normal     181500  \n2      9   2008        WD         Normal     223500  \n3      2   2006        WD        Abnorml     140000  \n4     12   2008        WD         Normal     250000  \n5     10   2009        WD         Normal     143000  \n6      8   2007        WD         Normal     307000  \n7     11   2009        WD         Normal     200000  \n8      4   2008        WD        Abnorml     129900  \n9      1   2008        WD         Normal     118000  \n\n[10 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "\n",
    "\n",
    "print(train[0:10])"
   ]
  },
  {
   "source": [
    "types = train.dtypes\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       RL\n1       RL\n2       RL\n3       RL\n4       RL\n        ..\n1455    RL\n1456    RL\n1457    RL\n1458    RL\n1459    RL\nName: MSZoning, Length: 1460, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "ke = train.columns[2]\n",
    "print(train[ke])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_dict = {}\n",
    "\n",
    "cat_labels = []\n",
    "new_arr = []\n",
    "first = True\n",
    "non_cat = []\n",
    "\n",
    "for ke, type in zip(train.columns, types):\n",
    "    if type == \"object\":\n",
    "        le = OneHotEncoder()\n",
    "        if train[ke].isnull().values.any():\n",
    "            ifnan = True\n",
    "        else:\n",
    "            ifnan = False\n",
    "\n",
    "        if ifnan:\n",
    "            unique = np.expand_dims(np.asarray([\"nan\"] + list(train[ke].dropna().unique())), axis = 1)\n",
    "        else:\n",
    "            unique = np.expand_dims(np.asarray(list(train[ke].dropna().unique())), axis = 1)\n",
    "\n",
    "\n",
    "        train[ke] = train[ke].fillna(\"nan\")\n",
    "\n",
    "        cat = le.fit_transform(np.expand_dims(train[ke], axis = 1)).toarray().T\n",
    "        if first:\n",
    "            first = False\n",
    "            categorical= cat\n",
    "        else:\n",
    "            categorical = np.concatenate((categorical, cat), axis = 0)\n",
    "\n",
    "        keys = le.categories_\n",
    "        ka = [k for k in keys]\n",
    "        cat_dict[ke] = ka\n",
    "        cat_labels.extend(ka)\n",
    "    else:\n",
    "        non_cat.append(ke)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = categorical.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1460, 304)\n"
     ]
    }
   ],
   "source": [
    "train_no_lab = train.iloc[:,1:-1]\n",
    "train_lab = train.iloc[:,-1]\n",
    "\n",
    "train_non_cat = train_no_lab[[t for t in train_no_lab.columns if t in non_cat]]\n",
    "\n",
    "train_arr = np.concatenate((train_non_cat, categorical), axis = 1)\n",
    "\n",
    "print(train_arr.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1460, 304)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "\n",
    "imputer.fit(train_arr)\n",
    "train_arr = imputer.transform(train_arr)\n",
    "print(train_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "##### Try Linear Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression(fit_intercept = False)\n",
    "reg.fit(train_arr, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9333483603038338\n"
     ]
    }
   ],
   "source": [
    "train_pred = reg.predict(train_arr)\n",
    "train_score = reg.score(train_arr, train_lab)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Trying LASSO\n",
    "from sklearn.linear_model import Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('env')",
   "metadata": {
    "interpreter": {
     "hash": "1bc38c910a2ac97386b6bf799a99b19782d7443e84f16a63e9afccf77f0414b4"
    }
   }
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}