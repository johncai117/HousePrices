{
 "cells": [
  {
   "source": [
    "# XGBOOST NOTEBOOK"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_lab = train.iloc[:,-1]\n",
    "train = train.iloc[:,:-1]\n",
    "\n",
    "train_len = train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       1461\n1       1462\n2       1463\n3       1464\n4       1465\n        ... \n1454    2915\n1455    2916\n1456    2917\n1457    2918\n1458    2919\nName: Id, Length: 1459, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([train, test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "def data_processor(df, train_len):\n",
    "    \n",
    "    types = df.dtypes\n",
    "    cat_dict = {}\n",
    "    cat_labels = []\n",
    "    new_arr = []\n",
    "    first = True\n",
    "    non_cat = []\n",
    "\n",
    "    for ke, type in zip(df.columns, types):\n",
    "        if type == \"object\":\n",
    "            le = OneHotEncoder()\n",
    "            if df[ke].isnull().values.any():\n",
    "                ifnan = True\n",
    "            else:\n",
    "                ifnan = False\n",
    "\n",
    "            if ifnan:\n",
    "                unique = np.expand_dims(np.asarray([\"nan\"] + list(df[ke].dropna().unique())), axis = 1)\n",
    "            else:\n",
    "                unique = np.expand_dims(np.asarray(list(df[ke].dropna().unique())), axis = 1)\n",
    "\n",
    "\n",
    "            df[ke] = df[ke].fillna(\"nan\")\n",
    "\n",
    "            cat = le.fit_transform(np.expand_dims(df[ke], axis = 1)).toarray().T\n",
    "            if first:\n",
    "                first = False\n",
    "                categorical= cat\n",
    "            else:\n",
    "                categorical = np.concatenate((categorical, cat), axis = 0)\n",
    "\n",
    "            keys = le.categories_\n",
    "            ka = [k for k in keys]\n",
    "            cat_dict[ke] = ka\n",
    "            cat_labels.extend(ka)\n",
    "        else:\n",
    "            non_cat.append(ke)\n",
    "    categorical = categorical.T\n",
    "\n",
    "    \n",
    "\n",
    "    df_non_cat = df[[t for t in df.columns if t in non_cat]]\n",
    "    print(df_non_cat.shape)\n",
    "\n",
    "    df_arr = np.concatenate((df_non_cat, categorical), axis = 1)\n",
    "    print(df_arr.shape)\n",
    "\n",
    "\n",
    "    train = df_arr[:train_len,1:]\n",
    "    test = df_arr[train_len:,1:]\n",
    "    test_idx = df_arr[train_len:,0]\n",
    "\n",
    "\n",
    "    return train, test, test_idx\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2919, 37)\n(2919, 312)\n"
     ]
    }
   ],
   "source": [
    "train_arr, test_arr, test_idx = data_processor(all, train_len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1461. 1462. 1463. ... 2917. 2918. 2919.]\n"
     ]
    }
   ],
   "source": [
    "print(test_idx)"
   ]
  },
  {
   "source": [
    "## Impute Missing Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "\n",
    "imputer.fit(train_arr)\n",
    "train_arr = imputer.transform(train_arr)\n",
    "test_arr = imputer.transform(test_arr)"
   ]
  },
  {
   "source": [
    "## Regression Trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.999521505381623\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "xg_reg.fit(train_arr, train_lab)\n",
    "\n",
    "y_pred = xg_reg.predict(train_arr)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(train_lab,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### hyperparameter tuning\n",
    "from sklearn.model_selection import cross_val_score\n",
    "alphas_xg = [s/2 for s in range(1,20)]\n",
    "\n",
    "cv_score_xg = []\n",
    "for alp in alphas_xg:\n",
    "    alp = alp/2\n",
    "    regr = xgb.XGBRegressor(objective ='reg:squarederror', reg_alpha = alp, reg_lambda = alp)\n",
    "    scores = cross_val_score(regr, train_arr, train_lab, cv = 5, scoring = 'r2')\n",
    "    cv_score_xg.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8735052176418175\n[4.0]\n"
     ]
    }
   ],
   "source": [
    "max_val = max(cv_score_xg)\n",
    "indices_max = [i for i,v in enumerate(cv_score_xg) if v == max_val]\n",
    "print(max_val)\n",
    "max_alphas_rf = [v for i,v in enumerate(alphas_xg) if i in indices_max]\n",
    "print(max_alphas_rf)"
   ]
  },
  {
   "source": [
    "### Importing test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=40, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=4.75, reg_lambda=4.75, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "xg_reg_final = xgb.XGBRegressor(objective ='reg:squarederror', reg_alpha = alp, reg_lambda = alp)\n",
    "xg_reg_final.fit(train_arr, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = xg_reg_final.predict(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df = pd.DataFrame({\"Id\":[int(x) for x in test_idx], \"SalePrice\":test_preds})\n",
    "test_pred_df = test_pred_df.set_index(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          SalePrice\nId                 \n1461  128812.609375\n1462  164200.546875\n1463  180234.906250\n1464  193567.625000\n1465  183337.109375\n...             ...\n2915   75945.093750\n2916   87261.507812\n2917  165403.312500\n2918  118890.593750\n2919  235937.734375\n\n[1459 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('env': venv)",
   "metadata": {
    "interpreter": {
     "hash": "1bc38c910a2ac97386b6bf799a99b19782d7443e84f16a63e9afccf77f0414b4"
    }
   }
  },
  "language_info": {
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}